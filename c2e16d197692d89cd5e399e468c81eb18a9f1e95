---
type: learnings
timestamp: '2025-12-27T15:41:14.086136+00:00'
summary: Telemetry pipeline works correctly but metrics appear empty until hooks execute
---

Telemetry pipeline works correctly but metrics appear empty until hooks execute
## Summary
The OTLP telemetry pipeline is fully functional. Metrics were appearing empty because few hooks had executed, not due to a configuration issue.

## Key Insights
- OTLP export from hooks works (http://localhost:4318)
- OTEL collector forwards to Prometheus via remote write
- Prometheus scrape interval is 15s - must wait for fresh data
- Metrics persist across hook invocations via ~/.local/share/memory-plugin/metrics_state.json
- Grafana dashboards are pre-configured at http://localhost:3000

## Related Files
- src/git_notes_memory/hooks/hook_utils.py:329-387 (timed_hook_execution context manager)
- src/git_notes_memory/observability/exporters/otlp.py:152-566 (OTLPExporter)
- src/git_notes_memory/observability/persistent_metrics.py:1-150 (persistence layer)

---
type: learnings
timestamp: '2025-12-27T15:44:25.475760+00:00'
summary: '▶ learned ─────────────────────────────────────

  Telemetry pipeline works correctly but metrics ap...'
tags:
- auto-captured
- pre-compact
---

Telemetry pipeline works correctly but metrics appear empty until hooks execute
## Summary
The OTLP telemetry pipeline is fully functional. Metrics were appearing empty because few hooks had executed, not due to a configuration issue.

## Key Insights
- OTLP export from hooks works (http://localhost:4318)
- OTEL collector forwards to Prometheus via remote write
- Prometheus scrape interval is 15s - must wait for fresh data
- Metrics persist across hook invocations via ~/.local/share/memory-plugin/metrics_state.json
- Grafana dashboards are pre-configured at http://localhost:3000

## Related Files
- src/git_notes_memory/hooks/hook_utils.py:329-387 (timed_hook_execution context manager)
- src/git_notes_memory/observability/exporters/otlp.py:152-566 (OTLPExporter)
- src/git_notes_memory/observability/persistent_metrics.py:1-150 (persistence layer)

---
type: learnings
timestamp: '2025-12-27T15:44:25.823591+00:00'
summary: '▶ learned ─────────────────────────────────────

  Memory blocks in Claude responses are output guid...'
tags:
- auto-captured
- pre-compact
---

Memory blocks in Claude responses are output guidance, not automatic captures
## Summary
The `▶ namespace` blocks Claude outputs are structured guidance for review - they don't automatically trigger memory capture or telemetry. Actual capture happens through explicit commands, hooks at session end, or the implicit capture agent.

## Key Points
- `▶ progress/decision/learned` blocks = formatting for human review
- Telemetry fires on: `/memory:capture`, Stop hook, implicit agent
- OTEL pipeline verified working: test metric appeared in Prometheus
- Dashboard queries now use correct `memory_*` prefixed metric names

## Related Files
- src/git_notes_memory/hooks/stop_handler.py (session-end capture)
- src/git_notes_memory/subconsciousness/implicit_capture_agent.py (LLM extraction)

---
type: learnings
timestamp: '2025-12-27T15:54:00.648510+00:00'
summary: '▶ learned ─────────────────────────────────────

  Telemetry pipeline works correctly but metrics ap...'
tags:
- auto-captured
- pre-compact
---

Telemetry pipeline works correctly but metrics appear empty until hooks execute
## Summary
The OTLP telemetry pipeline is fully functional. Metrics were appearing empty because few hooks had executed, not due to a configuration issue.

## Key Insights
- OTLP export from hooks works (http://localhost:4318)
- OTEL collector forwards to Prometheus via remote write
- Prometheus scrape interval is 15s - must wait for fresh data
- Metrics persist across hook invocations via ~/.local/share/memory-plugin/metrics_state.json
- Grafana dashboards are pre-configured at http://localhost:3000

## Related Files
- src/git_notes_memory/hooks/hook_utils.py:329-387 (timed_hook_execution context manager)
- src/git_notes_memory/observability/exporters/otlp.py:152-566 (OTLPExporter)
- src/git_notes_memory/observability/persistent_metrics.py:1-150 (persistence layer)

---
type: learnings
timestamp: '2025-12-27T15:54:00.973155+00:00'
summary: '▶ learned ─────────────────────────────────────

  Memory blocks in Claude responses are output guid...'
tags:
- auto-captured
- pre-compact
---

Memory blocks in Claude responses are output guidance, not automatic captures
## Summary
The `▶ namespace` blocks Claude outputs are structured guidance for review - they don't automatically trigger memory capture or telemetry. Actual capture happens through explicit commands, hooks at session end, or the implicit capture agent.

## Key Points
- `▶ progress/decision/learned` blocks = formatting for human review
- Telemetry fires on: `/memory:capture`, Stop hook, implicit agent
- OTEL pipeline verified working: test metric appeared in Prometheus
- Dashboard queries now use correct `memory_*` prefixed metric names

## Related Files
- src/git_notes_memory/hooks/stop_handler.py (session-end capture)
- src/git_notes_memory/subconsciousness/implicit_capture_agent.py (LLM extraction)

---
type: learnings
timestamp: '2025-12-27T16:05:51.759191+00:00'
summary: '▶ learned ─────────────────────────────────────

  Telemetry pipeline works correctly but metrics ap...'
tags:
- auto-captured
- pre-compact
---

Telemetry pipeline works correctly but metrics appear empty until hooks execute
## Summary
The OTLP telemetry pipeline is fully functional. Metrics were appearing empty because few hooks had executed, not due to a configuration issue.

## Key Insights
- OTLP export from hooks works (http://localhost:4318)
- OTEL collector forwards to Prometheus via remote write
- Prometheus scrape interval is 15s - must wait for fresh data
- Metrics persist across hook invocations via ~/.local/share/memory-plugin/metrics_state.json
- Grafana dashboards are pre-configured at http://localhost:3000

## Related Files
- src/git_notes_memory/hooks/hook_utils.py:329-387 (timed_hook_execution context manager)
- src/git_notes_memory/observability/exporters/otlp.py:152-566 (OTLPExporter)
- src/git_notes_memory/observability/persistent_metrics.py:1-150 (persistence layer)

---
type: learnings
timestamp: '2025-12-27T16:05:52.095743+00:00'
summary: '▶ learned ─────────────────────────────────────

  Memory blocks in Claude responses are output guid...'
tags:
- auto-captured
- pre-compact
---

Memory blocks in Claude responses are output guidance, not automatic captures
## Summary
The `▶ namespace` blocks Claude outputs are structured guidance for review - they don't automatically trigger memory capture or telemetry. Actual capture happens through explicit commands, hooks at session end, or the implicit capture agent.

## Key Points
- `▶ progress/decision/learned` blocks = formatting for human review
- Telemetry fires on: `/memory:capture`, Stop hook, implicit agent
- OTEL pipeline verified working: test metric appeared in Prometheus
- Dashboard queries now use correct `memory_*` prefixed metric names

## Related Files
- src/git_notes_memory/hooks/stop_handler.py (session-end capture)
- src/git_notes_memory/subconsciousness/implicit_capture_agent.py (LLM extraction)

---
type: learnings
timestamp: '2025-12-27T16:19:29.189836+00:00'
summary: '▶ learned ─────────────────────────────────────

  Telemetry pipeline works correctly but metrics ap...'
tags:
- auto-captured
- pre-compact
---

Telemetry pipeline works correctly but metrics appear empty until hooks execute
## Summary
The OTLP telemetry pipeline is fully functional. Metrics were appearing empty because few hooks had executed, not due to a configuration issue.

## Key Insights
- OTLP export from hooks works (http://localhost:4318)
- OTEL collector forwards to Prometheus via remote write
- Prometheus scrape interval is 15s - must wait for fresh data
- Metrics persist across hook invocations via ~/.local/share/memory-plugin/metrics_state.json
- Grafana dashboards are pre-configured at http://localhost:3000

## Related Files
- src/git_notes_memory/hooks/hook_utils.py:329-387 (timed_hook_execution context manager)
- src/git_notes_memory/observability/exporters/otlp.py:152-566 (OTLPExporter)
- src/git_notes_memory/observability/persistent_metrics.py:1-150 (persistence layer)

---
type: learnings
timestamp: '2025-12-27T16:19:29.530158+00:00'
summary: '▶ learned ─────────────────────────────────────

  Memory blocks in Claude responses are output guid...'
tags:
- auto-captured
- pre-compact
---

Memory blocks in Claude responses are output guidance, not automatic captures
## Summary
The `▶ namespace` blocks Claude outputs are structured guidance for review - they don't automatically trigger memory capture or telemetry. Actual capture happens through explicit commands, hooks at session end, or the implicit capture agent.

## Key Points
- `▶ progress/decision/learned` blocks = formatting for human review
- Telemetry fires on: `/memory:capture`, Stop hook, implicit agent
- OTEL pipeline verified working: test metric appeared in Prometheus
- Dashboard queries now use correct `memory_*` prefixed metric names

## Related Files
- src/git_notes_memory/hooks/stop_handler.py (session-end capture)
- src/git_notes_memory/subconsciousness/implicit_capture_agent.py (LLM extraction)

---
type: learnings
timestamp: '2025-12-27T16:34:04.715765+00:00'
summary: '▶ learned ─────────────────────────────────────

  Telemetry pipeline works correctly but metrics ap...'
tags:
- auto-captured
- pre-compact
---

Telemetry pipeline works correctly but metrics appear empty until hooks execute
## Summary
The OTLP telemetry pipeline is fully functional. Metrics were appearing empty because few hooks had executed, not due to a configuration issue.

## Key Insights
- OTLP export from hooks works (http://localhost:4318)
- OTEL collector forwards to Prometheus via remote write
- Prometheus scrape interval is 15s - must wait for fresh data
- Metrics persist across hook invocations via ~/.local/share/memory-plugin/metrics_state.json
- Grafana dashboards are pre-configured at http://localhost:3000

## Related Files
- src/git_notes_memory/hooks/hook_utils.py:329-387 (timed_hook_execution context manager)
- src/git_notes_memory/observability/exporters/otlp.py:152-566 (OTLPExporter)
- src/git_notes_memory/observability/persistent_metrics.py:1-150 (persistence layer)

---
type: learnings
timestamp: '2025-12-27T16:34:05.025265+00:00'
summary: '▶ learned ─────────────────────────────────────

  Memory blocks in Claude responses are output guid...'
tags:
- auto-captured
- pre-compact
---

Memory blocks in Claude responses are output guidance, not automatic captures
## Summary
The `▶ namespace` blocks Claude outputs are structured guidance for review - they don't automatically trigger memory capture or telemetry. Actual capture happens through explicit commands, hooks at session end, or the implicit capture agent.

## Key Points
- `▶ progress/decision/learned` blocks = formatting for human review
- Telemetry fires on: `/memory:capture`, Stop hook, implicit agent
- OTEL pipeline verified working: test metric appeared in Prometheus
- Dashboard queries now use correct `memory_*` prefixed metric names

## Related Files
- src/git_notes_memory/hooks/stop_handler.py (session-end capture)
- src/git_notes_memory/subconsciousness/implicit_capture_agent.py (LLM extraction)

---
type: learnings
timestamp: '2025-12-27T16:34:05.561307+00:00'
summary: Now I understand the schema structure. For Task 2.5, I need to extend the
  index schema to support...
tags:
- auto-captured
- pre-compact
---

Now I understand the schema structure. For Task 2.5, I need to extend the index schema to support consolidation...

---
type: learnings
timestamp: '2025-12-27T16:37:09.828560+00:00'
summary: '...consolidation.'
tags:
- auto-captured
- post-tool-use
- file:retention.py
---

...consolidation.

This module implements the retention scoring algorithm that determines
how important a memory is to keep in the active (hot/warm) tiers.

The retention score is a weighted combination...

---
type: learnings
timestamp: '2025-12-27T16:39:07.506596+00:00'
summary: '...@pytest.fixture'
tags:
- auto-captured
- post-tool-use
- file:test_retention.py
---

...@pytest.fixture
    def recent_hot_memory(self) -> Memory:
        """Create a recent, important memory."""
        return Memory(
            id="decisions:abc1234:0",
            namespace="decisions...

---
type: learnings
timestamp: '2025-12-27T16:39:07.545655+00:00'
summary: '...important_memory_high_score('
tags:
- auto-captured
- post-tool-use
- file:test_retention.py
---

...important_memory_high_score(
        self, recent_hot_memory: Memory
    ) -> None:
        """Test recent important memory has high score."""
        score = compute_retention_score(recent_hot_memory)...

---
type: learnings
timestamp: '2025-12-27T16:39:07.568962+00:00'
summary: '...superseded'
tags:
- auto-captured
- post-tool-use
- file:test_retention.py
---

...superseded
        assert score.supersession_penalty == SUPERSESSION_PENALTY
        # Even a recent important memory gets low score when superseded
        assert score.overall < 0.5

    def test_score_has_factor...

---
type: learnings
timestamp: '2025-12-27T16:40:43.264365+00:00'
summary: '...@pytest.fixture'
tags:
- auto-captured
- post-tool-use
- file:test_retention.py
---

...@pytest.fixture
    def recent_hot_memory(self) -> Memory:
        """Create a recent, important memory."""
        return Memory(
            id="decisions:abc1234:0",
            commit_sha="abc1234...

---
type: learnings
timestamp: '2025-12-27T16:42:58.092129+00:00'
summary: '▶ learned ─────────────────────────────────────

  Telemetry pipeline works correctly but metrics ap...'
tags:
- auto-captured
- pre-compact
---

Telemetry pipeline works correctly but metrics appear empty until hooks execute
## Summary
The OTLP telemetry pipeline is fully functional. Metrics were appearing empty because few hooks had executed, not due to a configuration issue.

## Key Insights
- OTLP export from hooks works (http://localhost:4318)
- OTEL collector forwards to Prometheus via remote write
- Prometheus scrape interval is 15s - must wait for fresh data
- Metrics persist across hook invocations via ~/.local/share/memory-plugin/metrics_state.json
- Grafana dashboards are pre-configured at http://localhost:3000

## Related Files
- src/git_notes_memory/hooks/hook_utils.py:329-387 (timed_hook_execution context manager)
- src/git_notes_memory/observability/exporters/otlp.py:152-566 (OTLPExporter)
- src/git_notes_memory/observability/persistent_metrics.py:1-150 (persistence layer)

---
type: learnings
timestamp: '2025-12-27T16:42:58.400136+00:00'
summary: '▶ learned ─────────────────────────────────────

  Memory blocks in Claude responses are output guid...'
tags:
- auto-captured
- pre-compact
---

Memory blocks in Claude responses are output guidance, not automatic captures
## Summary
The `▶ namespace` blocks Claude outputs are structured guidance for review - they don't automatically trigger memory capture or telemetry. Actual capture happens through explicit commands, hooks at session end, or the implicit capture agent.

## Key Points
- `▶ progress/decision/learned` blocks = formatting for human review
- Telemetry fires on: `/memory:capture`, Stop hook, implicit agent
- OTEL pipeline verified working: test metric appeared in Prometheus
- Dashboard queries now use correct `memory_*` prefixed metric names

## Related Files
- src/git_notes_memory/hooks/stop_handler.py (session-end capture)
- src/git_notes_memory/subconsciousness/implicit_capture_agent.py (LLM extraction)

---
type: learnings
timestamp: '2025-12-27T16:42:59.045241+00:00'
summary: Now I understand the schema structure. For Task 2.5, I need to extend the
  index schema to support...
tags:
- auto-captured
- pre-compact
---

Now I understand the schema structure. For Task 2.5, I need to extend the index schema to support consolidation...

---
type: learnings
timestamp: '2025-12-27T16:53:30.190892+00:00'
summary: '▶ learned ─────────────────────────────────────

  Telemetry pipeline works correctly but metrics ap...'
tags:
- auto-captured
- pre-compact
---

Telemetry pipeline works correctly but metrics appear empty until hooks execute
## Summary
The OTLP telemetry pipeline is fully functional. Metrics were appearing empty because few hooks had executed, not due to a configuration issue.

## Key Insights
- OTLP export from hooks works (http://localhost:4318)
- OTEL collector forwards to Prometheus via remote write
- Prometheus scrape interval is 15s - must wait for fresh data
- Metrics persist across hook invocations via ~/.local/share/memory-plugin/metrics_state.json
- Grafana dashboards are pre-configured at http://localhost:3000

## Related Files
- src/git_notes_memory/hooks/hook_utils.py:329-387 (timed_hook_execution context manager)
- src/git_notes_memory/observability/exporters/otlp.py:152-566 (OTLPExporter)
- src/git_notes_memory/observability/persistent_metrics.py:1-150 (persistence layer)

---
type: learnings
timestamp: '2025-12-27T16:53:30.503357+00:00'
summary: '▶ learned ─────────────────────────────────────

  Memory blocks in Claude responses are output guid...'
tags:
- auto-captured
- pre-compact
---

Memory blocks in Claude responses are output guidance, not automatic captures
## Summary
The `▶ namespace` blocks Claude outputs are structured guidance for review - they don't automatically trigger memory capture or telemetry. Actual capture happens through explicit commands, hooks at session end, or the implicit capture agent.

## Key Points
- `▶ progress/decision/learned` blocks = formatting for human review
- Telemetry fires on: `/memory:capture`, Stop hook, implicit agent
- OTEL pipeline verified working: test metric appeared in Prometheus
- Dashboard queries now use correct `memory_*` prefixed metric names

## Related Files
- src/git_notes_memory/hooks/stop_handler.py (session-end capture)
- src/git_notes_memory/subconsciousness/implicit_capture_agent.py (LLM extraction)

---
type: learnings
timestamp: '2025-12-27T16:53:31.268407+00:00'
summary: Now I understand the schema structure. For Task 2.5, I need to extend the
  index schema to support...
tags:
- auto-captured
- pre-compact
---

Now I understand the schema structure. For Task 2.5, I need to extend the index schema to support consolidation...

---
type: learnings
timestamp: '2025-12-27T17:07:59.497607+00:00'
summary: '▶ learned ─────────────────────────────────────

  Telemetry pipeline works correctly but metrics ap...'
tags:
- auto-captured
- pre-compact
---

Telemetry pipeline works correctly but metrics appear empty until hooks execute
## Summary
The OTLP telemetry pipeline is fully functional. Metrics were appearing empty because few hooks had executed, not due to a configuration issue.

## Key Insights
- OTLP export from hooks works (http://localhost:4318)
- OTEL collector forwards to Prometheus via remote write
- Prometheus scrape interval is 15s - must wait for fresh data
- Metrics persist across hook invocations via ~/.local/share/memory-plugin/metrics_state.json
- Grafana dashboards are pre-configured at http://localhost:3000

## Related Files
- src/git_notes_memory/hooks/hook_utils.py:329-387 (timed_hook_execution context manager)
- src/git_notes_memory/observability/exporters/otlp.py:152-566 (OTLPExporter)
- src/git_notes_memory/observability/persistent_metrics.py:1-150 (persistence layer)

---
type: learnings
timestamp: '2025-12-27T17:07:59.847561+00:00'
summary: '▶ learned ─────────────────────────────────────

  Memory blocks in Claude responses are output guid...'
tags:
- auto-captured
- pre-compact
---

Memory blocks in Claude responses are output guidance, not automatic captures
## Summary
The `▶ namespace` blocks Claude outputs are structured guidance for review - they don't automatically trigger memory capture or telemetry. Actual capture happens through explicit commands, hooks at session end, or the implicit capture agent.

## Key Points
- `▶ progress/decision/learned` blocks = formatting for human review
- Telemetry fires on: `/memory:capture`, Stop hook, implicit agent
- OTEL pipeline verified working: test metric appeared in Prometheus
- Dashboard queries now use correct `memory_*` prefixed metric names

## Related Files
- src/git_notes_memory/hooks/stop_handler.py (session-end capture)
- src/git_notes_memory/subconsciousness/implicit_capture_agent.py (LLM extraction)

---
type: learnings
timestamp: '2025-12-27T17:08:00.827282+00:00'
summary: Now I understand the schema structure. For Task 2.5, I need to extend the
  index schema to support...
tags:
- auto-captured
- pre-compact
---

Now I understand the schema structure. For Task 2.5, I need to extend the index schema to support consolidation...

---
type: learnings
timestamp: '2025-12-27T17:17:24.388451+00:00'
summary: '▶ learned ─────────────────────────────────────

  Telemetry pipeline works correctly but metrics ap...'
tags:
- auto-captured
- pre-compact
---

Telemetry pipeline works correctly but metrics appear empty until hooks execute
## Summary
The OTLP telemetry pipeline is fully functional. Metrics were appearing empty because few hooks had executed, not due to a configuration issue.

## Key Insights
- OTLP export from hooks works (http://localhost:4318)
- OTEL collector forwards to Prometheus via remote write
- Prometheus scrape interval is 15s - must wait for fresh data
- Metrics persist across hook invocations via ~/.local/share/memory-plugin/metrics_state.json
- Grafana dashboards are pre-configured at http://localhost:3000

## Related Files
- src/git_notes_memory/hooks/hook_utils.py:329-387 (timed_hook_execution context manager)
- src/git_notes_memory/observability/exporters/otlp.py:152-566 (OTLPExporter)
- src/git_notes_memory/observability/persistent_metrics.py:1-150 (persistence layer)

---
type: learnings
timestamp: '2025-12-27T17:17:24.724527+00:00'
summary: '▶ learned ─────────────────────────────────────

  Memory blocks in Claude responses are output guid...'
tags:
- auto-captured
- pre-compact
---

Memory blocks in Claude responses are output guidance, not automatic captures
## Summary
The `▶ namespace` blocks Claude outputs are structured guidance for review - they don't automatically trigger memory capture or telemetry. Actual capture happens through explicit commands, hooks at session end, or the implicit capture agent.

## Key Points
- `▶ progress/decision/learned` blocks = formatting for human review
- Telemetry fires on: `/memory:capture`, Stop hook, implicit agent
- OTEL pipeline verified working: test metric appeared in Prometheus
- Dashboard queries now use correct `memory_*` prefixed metric names

## Related Files
- src/git_notes_memory/hooks/stop_handler.py (session-end capture)
- src/git_notes_memory/subconsciousness/implicit_capture_agent.py (LLM extraction)

---
type: learnings
timestamp: '2025-12-27T17:17:25.694874+00:00'
summary: Now I understand the schema structure. For Task 2.5, I need to extend the
  index schema to support...
tags:
- auto-captured
- pre-compact
---

Now I understand the schema structure. For Task 2.5, I need to extend the index schema to support consolidation...

---
type: learnings
timestamp: '2025-12-27T17:42:52.646078+00:00'
summary: '▶ learned ─────────────────────────────────────

  Telemetry pipeline works correctly but metrics ap...'
tags:
- auto-captured
- pre-compact
---

Telemetry pipeline works correctly but metrics appear empty until hooks execute
## Summary
The OTLP telemetry pipeline is fully functional. Metrics were appearing empty because few hooks had executed, not due to a configuration issue.

## Key Insights
- OTLP export from hooks works (http://localhost:4318)
- OTEL collector forwards to Prometheus via remote write
- Prometheus scrape interval is 15s - must wait for fresh data
- Metrics persist across hook invocations via ~/.local/share/memory-plugin/metrics_state.json
- Grafana dashboards are pre-configured at http://localhost:3000

## Related Files
- src/git_notes_memory/hooks/hook_utils.py:329-387 (timed_hook_execution context manager)
- src/git_notes_memory/observability/exporters/otlp.py:152-566 (OTLPExporter)
- src/git_notes_memory/observability/persistent_metrics.py:1-150 (persistence layer)

---
type: learnings
timestamp: '2025-12-27T17:42:53.030695+00:00'
summary: '▶ learned ─────────────────────────────────────

  Memory blocks in Claude responses are output guid...'
tags:
- auto-captured
- pre-compact
---

Memory blocks in Claude responses are output guidance, not automatic captures
## Summary
The `▶ namespace` blocks Claude outputs are structured guidance for review - they don't automatically trigger memory capture or telemetry. Actual capture happens through explicit commands, hooks at session end, or the implicit capture agent.

## Key Points
- `▶ progress/decision/learned` blocks = formatting for human review
- Telemetry fires on: `/memory:capture`, Stop hook, implicit agent
- OTEL pipeline verified working: test metric appeared in Prometheus
- Dashboard queries now use correct `memory_*` prefixed metric names

## Related Files
- src/git_notes_memory/hooks/stop_handler.py (session-end capture)
- src/git_notes_memory/subconsciousness/implicit_capture_agent.py (LLM extraction)

---
type: learnings
timestamp: '2025-12-27T17:42:54.168821+00:00'
summary: Now I understand the schema structure. For Task 2.5, I need to extend the
  index schema to support...
tags:
- auto-captured
- pre-compact
---

Now I understand the schema structure. For Task 2.5, I need to extend the index schema to support consolidation...

---
type: learnings
timestamp: '2025-12-27T17:55:23.226531+00:00'
summary: '...create_mock_summary()'
tags:
- auto-captured
- post-tool-use
- file:test_summary_injector.py
---

...create_mock_summary()
        injector.set_summaries([summary])

        context = "<memory_context>Important content</memory_context>"
        result = injector.inject_summaries(context)

        assert...

---
type: learnings
timestamp: '2025-12-27T17:55:23.250737+00:00'
summary: '...content</memory_context>"'
tags:
- auto-captured
- post-tool-use
- file:test_summary_injector.py
---

...content</memory_context>"
        result = injector.inject_summaries(context)

        assert "Important content" in result.modified_context
        assert "<memory_consolidated_summaries>" in result.modified...

---
type: learnings
timestamp: '2025-12-27T17:56:57.432757+00:00'
summary: '▶ learned ─────────────────────────────────────

  Telemetry pipeline works correctly but metrics ap...'
tags:
- auto-captured
- pre-compact
---

Telemetry pipeline works correctly but metrics appear empty until hooks execute
## Summary
The OTLP telemetry pipeline is fully functional. Metrics were appearing empty because few hooks had executed, not due to a configuration issue.

## Key Insights
- OTLP export from hooks works (http://localhost:4318)
- OTEL collector forwards to Prometheus via remote write
- Prometheus scrape interval is 15s - must wait for fresh data
- Metrics persist across hook invocations via ~/.local/share/memory-plugin/metrics_state.json
- Grafana dashboards are pre-configured at http://localhost:3000

## Related Files
- src/git_notes_memory/hooks/hook_utils.py:329-387 (timed_hook_execution context manager)
- src/git_notes_memory/observability/exporters/otlp.py:152-566 (OTLPExporter)
- src/git_notes_memory/observability/persistent_metrics.py:1-150 (persistence layer)

---
type: learnings
timestamp: '2025-12-27T17:56:57.795257+00:00'
summary: '▶ learned ─────────────────────────────────────

  Memory blocks in Claude responses are output guid...'
tags:
- auto-captured
- pre-compact
---

Memory blocks in Claude responses are output guidance, not automatic captures
## Summary
The `▶ namespace` blocks Claude outputs are structured guidance for review - they don't automatically trigger memory capture or telemetry. Actual capture happens through explicit commands, hooks at session end, or the implicit capture agent.

## Key Points
- `▶ progress/decision/learned` blocks = formatting for human review
- Telemetry fires on: `/memory:capture`, Stop hook, implicit agent
- OTEL pipeline verified working: test metric appeared in Prometheus
- Dashboard queries now use correct `memory_*` prefixed metric names

## Related Files
- src/git_notes_memory/hooks/stop_handler.py (session-end capture)
- src/git_notes_memory/subconsciousness/implicit_capture_agent.py (LLM extraction)

---
type: learnings
timestamp: '2025-12-27T17:56:59.000093+00:00'
summary: Now I understand the schema structure. For Task 2.5, I need to extend the
  index schema to support...
tags:
- auto-captured
- pre-compact
---

Now I understand the schema structure. For Task 2.5, I need to extend the index schema to support consolidation...

---
type: learnings
timestamp: '2025-12-27T18:02:22.883035+00:00'
summary: '...summaries([create_mock_summary()])'
tags:
- auto-captured
- post-tool-use
- file:test_hook_integration.py
---

...summaries([create_mock_summary()])

        original = """<memory_context>
<working_memory>
<blockers>Important blocker</blockers>
</working_memory>
</memory_context>"""

        result = service.inject_consolidated...

---
type: learnings
timestamp: '2025-12-27T18:02:22.924557+00:00'
summary: '...consolidated_summaries(original, context)'
tags:
- auto-captured
- post-tool-use
- file:test_hook_integration.py
---

...consolidated_summaries(original, context)

        # Original content should be preserved
        assert "Important blocker" in result.modified_context
        assert "working_memory" in result.modified_context

#...

---
type: learnings
timestamp: '2025-12-27T18:04:23.991225+00:00'
summary: '..."""Test that original content is preserved."""'
tags:
- auto-captured
- post-tool-use
- file:test_hook_integration.py
---

..."""Test that original content is preserved."""
        original = "<memory_context>Important content</memory_context>"

        result = get_session_start_additional_context(...

---
type: learnings
timestamp: '2025-12-27T18:04:24.033467+00:00'
summary: '...event_data={"cwd": "/path"},'
tags:
- auto-captured
- post-tool-use
- file:test_hook_integration.py
---

...event_data={"cwd": "/path"},
            project="test",
        )

        assert "Important content" in result

    def test_with_spec_id(self) -> None:
        """Test function with...
